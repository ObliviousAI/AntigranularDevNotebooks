{
 "cells": [
  {
   "attachments": {},
   "cell<user_secret>type": "markdown",
   "metadata": {},
   "source": [
    "# Antigranular: Sample Notebook\n",
    "\n",
    "This notebook is a sample notebook for the Antigranular project. It demonstrates use of the antigranular client package to connect to antigranular enclave server running on network of Oblivious Enclaves. \n",
    "\n",
    "Running inside the enclave is a restricted python-like runtime managed as a Jupyter kernel. It uses static and dynamic analysis to enforce static typing, scoping constraints and a limited api to interfact with private or sensitive data sources. \n",
    "\n",
    "The two core technical components the enforce our privacy constraints for data scientists are:\n",
    "- Secure Enclaves (A form of input privacy)\n",
    "- Differential Privacy (A form of output privacy)\n",
    "\n",
    "### What are secure enclaves?\n",
    "\n",
    "Secure enclaves are isolated servers with two very powerful properties:\n",
    "\n",
    "They have extremely limitted IO and need explicit inbound and outbound connections to recieve and send data. No one can simply SSH into an enclave and see data as it is being processed, nor can data end up unexpectedly in log files.\n",
    "The underlying infrastructure \"attests\" what is running inside. So when we write some software to deploy into an enclave, the physical infrastructure will hash the software and environment and place these values into a document which it digitally signs. In short, the cloud infrastructure implicitly gaurentees to those connecting to the enclave the exact processing and behaviour of what is running inside the enclave.\n",
    "\n",
    "This is extremely powerful as we can use these charecteristics to clearly structure rules around what processes can decrypt what data (not what servers, or people - what actual computation is approved!). AS you can imagine, all of the major cloud providers have developed an enclave offering of one form or another (AWS, Azure, GP<user_id>, Alibaba Cloud, IBM, Oracle, OVH Cloud.... the list goes on) over the past few years and billions worth of investments have been poored into the domain.\n",
    "\n",
    "### What is Differential Privacy? \n",
    "  \n",
    "While this workshop focuses on synthetic data, there are different approaches to creating synthetic data. The only method which gives a theoretical privacy guarantee is called Differentially Private (DP) synthetic data.\n",
    "  \n",
    "Differential privacy, coined in [2006 by Cynthia Dwork, Frank McSherry, Kobbi Nissim and Adam D. Smith](https://link.springer.com/chapter/10.1007/11681878_14), is a theoretical statement about the guessing probability of data being present in a dataset given stochastic measurements/queries of the dataset (intuitively: any information gained that is derived from the dataset). Some processes may naturally create stochastic measurements; however, in most cases, calibrated noise is intentionally applied to a result of measurement such that the measurement will be differentially private. \n",
    "  \n",
    "This privacy framework ultimately relies on what you want the guessing probability to be, and there is a natural trade-off between the accuracy of a measurement and the guessing probability. Strictly speaking, this guessing probability is parameterised by a coefficient ε. If ε is 0, the measurement discloses no information about the data being in the dataset, so the guessing probability is uniform (50:50). If ε is infinite, then the measurement discloses with absolute certainty whether the data is present or not in the dataset.\n",
    "\n",
    "$$ \\epsilon \\geq \\ln \\left( \\frac{Pr[M(x) \\in S]}{Pr[M(x') \\in S]} \\right) $$\n",
    "  \n",
    "There is no golden rule in selecting an acceptable ε which you can deem \"safe”, and you will likely need to decide internally what you believe to be a reasonable risk.\n",
    "  \n",
    "Finally, the ε of multiple measurements/queries can interact in complicated ways. However, it is straightforward to upper bound the worst case ε by the sum of all of the ε: $\\epsilon = \\sum_{i=0}^{n} \\epsilon_i$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Privacy into the Code Block\n",
    "\n",
    "In order to combine input and output privacy, we provide a framework for remotecode execution the feels somewhat native to the data science user experience. The steps are essentially:\n",
    "\n",
    "- Connect to a enclave backend.\n",
    "- Use the `%%ag` magic to send blocks of code for remote execution.\n",
    "- Manipulate and query data in the safety of the enclave and export only public data (post-DP) to the client.\n",
    "\n",
    "To get started we import the antigranular package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import antigranular as ag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log In with OAuth\n",
    "\n",
    "We use standard OAuth to authenticate users despite doing the full attestation based handshake to authenticate the software running within the enclave. In the example below, you can ignore the temp_user/password, this is only in place for local testing and demos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Antigranular server session id: 3f23b120-07a9-41da-9cf4-8b663821776a\n",
      "Cell magic '%%ag' registered successfully, use `%%ag` in a notebook cell to execute your python code on Antigranular private python server\n"
     ]
    }
   ],
   "source": [
    "ag_client  = ag.login(user_id=\"CDl6m0dfjtOPYzZUkvSDznKMKWVaEGCg\", user_secret=\"_l5cUr6fGGm5hNY2mHhSQboMIWWPWnls2bGqsTJ90daCtSMnL1GscxUtmWUCxeX-\", dataset=\"Iris Dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've logged in you will have a session id associated with your interactions. This actually gets embedded into the ipynb metadata so when you share your notebook we can associate it with your score from a competition, or you metrics associated with analysing a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3f23b120-07a9-41da-9cf4-8b663821776a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_client.session_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Code with AG\n",
    "\n",
    "We have used magic `%%ag` to let user toggle between private python and regular. Simply, add it to the top of any cell and your code will be remotely executed. Any non-private data type (int, float, list, str, etc) can be exported back to your current Jupyter instance using the `export` method as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up exported variable in local environment: x\n"
     ]
    }
   ],
   "source": [
    "%%ag \n",
    "from ag_utils import export \n",
    "\n",
    "export(2, \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look what's in x now in your local Jupyter session: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Look what's in x now in your local Jupyter session:\", x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throwing Errors\n",
    "\n",
    "Errors can be thrown for a variety of reasons. Antigranular restrict many AST nodes, enforces strict mypy, limits the scopes of variable assignments and much more. If you try to do any of these you will be greated with an error message which is forwarded to your local runtime:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the scope intensionally to limit the side effects of a method call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)File \u001b[0;32m/code/dependencies/ag-private-kernel/kernel/compiler/restricted.py:20\u001b[0m, in \u001b[0;36mRestrictedCachingCompiler.__call__\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m     symbol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m     19\u001b[0m unparsed_source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39munparse(source)\n",
      "\u001b[0;32m---> 20\u001b[0m code_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_and_compile\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munparsed_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbol\u001b[49m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m _features:\n",
      "\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m code_obj\u001b[38;5;241m.\u001b[39mco_flags \u001b[38;5;241m&\u001b[39m feature\u001b[38;5;241m.\u001b[39mcompiler_flag:\n",
      "File \u001b[0;32m/code/dependencies/ag-engine/ag_engine/parser.py:56\u001b[0m, in \u001b[0;36mParser.parse_and_compile\u001b[0;34m(self, code, filename, mode)\u001b[0m\n",
      "\u001b[1;32m     53\u001b[0m total_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_history) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m code\n",
      "\u001b[1;32m     55\u001b[0m ast \u001b[38;5;241m=\u001b[39m AST(code\u001b[38;5;241m=\u001b[39mtotal_code)\n",
      "\u001b[0;32m---> 56\u001b[0m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     58\u001b[0m sym \u001b[38;5;241m=\u001b[39m Symtable(code\u001b[38;5;241m=\u001b[39mtotal_code, allowed_global_symbols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_globals)\n",
      "\u001b[1;32m     59\u001b[0m sym\u001b[38;5;241m.\u001b[39msymtable_check()\n",
      "File \u001b[0;32m/code/dependencies/ag-engine/ag_engine/static_analysis/ast_walk.py:16\u001b[0m, in \u001b[0;36mAST.check\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m ast\u001b[38;5;241m.\u001b[39mwalk(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_code):\n",
      "\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m default_config\u001b[38;5;241m.\u001b[39mast_allowed:\n",
      "\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestricted, Cannot use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in pripy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# adding imports\u001b[39;00m\n",
      "\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, ast\u001b[38;5;241m.\u001b[39mImport):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Restricted, Cannot use <ast.Global object at 0x7f389fd373a0> in pripy\n"
     ]
    }
   ],
   "source": [
    "%%ag \n",
    "r = 1\n",
    "r = r + 1\n",
    "\n",
    "def goofie() -> None:\n",
    "    # same is true for any free, nonlocal, global vars\n",
    "    # either implicitly or explicitly defined...\n",
    "    global r\n",
    "    r = 6\n",
    "    \n",
    "goofie()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private DataFrames \n",
    "\n",
    "Usually the dataset you are looking for will already be present in the session you connect into, however we'll show you how these are constructed first and then how we can use most of the common pandas interfaces in a differentially private mannor to gain insights into the underlying dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)Cell \u001b[0;32mIn[4], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mop_pandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrivateDataFrame\n",
      "\u001b[0;31mTypeError\u001b[0m: PrivateDataFrame.__init__() got an unexpected keyword argument '_id'\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from op_pandas import PrivateDataFrame\n",
    "\n",
    "# create the priate dataframe. This is usually done for you.\n",
    "df = pd.DataFrame(np.random.randint(10, size=(1000, 2)), columns=[\"Example\", \"Example2\"])\n",
    "pdf = PrivateDataFrame(df, metadata={\"Example\": (0, 10), \"Example2\": (0, 10)}, _id=1234567890)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask statistical questions from the private dataframe by spending some of our privacy budget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)Cell \u001b[0;32mIn[5], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m export(pdf\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      2\u001b[0m export(pdf\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      3\u001b[0m export(pdf\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pdf' is not defined\n"
     ]
    }
   ],
   "source": [
    "%%ag\n",
    "export(pdf.sum(1), \"sum_\")\n",
    "export(pdf.mean(1), \"mean_\")\n",
    "export(pdf.std(1), \"std_\")\n",
    "export(pdf.count(1), \"count_\")\n",
    "export(pdf.var(1), \"var_\")\n",
    "export(pdf.median(1), \"median_\")\n",
    "export(pdf.quantile(0.25), \"quantile_\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once exported we can plot them, print them, whatever you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe sum was:\u001b[39m\u001b[39m\"\u001b[39m, sum_)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe mean was:\u001b[39m\u001b[39m\"\u001b[39m, mean_)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe std was:\u001b[39m\u001b[39m\"\u001b[39m, std_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sum_' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"The sum was:\", sum_)\n",
    "print(\"The mean was:\", mean_)\n",
    "print(\"The std was:\", std_)\n",
    "print(\"The count was:\", count_)\n",
    "print(\"The var was:\", var_)\n",
    "print(\"The median was:\", median_)\n",
    "print(\"The quantile was:\", quantile_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit Learn with DiffPrivLib \n",
    "\n",
    "One of the beauties of of the python ecosystem is the rich landscape of frameworks for data science. Fortunately, there are drop in replacements for a number of these which preserve differential privacy. One convenient one is DiffPrivLib written by Naoise Holohan at IBM Research. \n",
    "\n",
    "Let's go ahead and train a random forest with differential privacy, for example, on our dataset and download the resulting model to our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from op_pandas import PrivateDataFrame , PrivateSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "import pandas as pd\n",
    "s = pd.Series([1,5,8,2,9])\n",
    "priv_s = PrivateSeries(series=s,metadata=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Age':[20,30,40,25],\n",
    "    'Salary':[35000,60000,100000,55000],\n",
    "    'Sex':['M','F','M','F']\n",
    "}\n",
    "metadata = {\n",
    "    'Age':(18,65),\n",
    "    'Salary':(20000,200000)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "priv_df = PrivateDataFrame(df=df , metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from op_pandas import PrivateDataFrame , PrivateSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random_data = {\n",
    "    'Age': np.random.randint(18, 60, size=100000),\n",
    "    'Salary': np.random.randint(40000, 200000, size=100000),\n",
    "    'DOB': pd.date_range('1970-01-01', periods=100000, freq='D').strftime('%Y-%m-%d')\n",
    "}\n",
    "df = pd.DataFrame(random_data)\n",
    "priv_df = PrivateDataFrame(df,metadata={'Age':(18,60) , 'Salary':(40000,200000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "priv_describe = priv_df.describe(eps=1)\n",
    "# Export information from remote ag kernel to local jupyter server.\n",
    "export(priv_describe , 'df_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "priv_s = priv_df[\"Age\"]\n",
    "export(priv_s.describe(eps=1) , \"Age_series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Age_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "\n",
    "from ag_utils import export\n",
    "# maps string to its length if not numerical else divides it by 2.\n",
    "def func(x: str | int | float) -> float:\n",
    "    if isinstance(x, str):\n",
    "        return len(x)\n",
    "    elif isinstance(x, (int, float)):\n",
    "        return x / 2\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "result = priv_df.applymap(func,eps=1)\n",
    "export(result.describe(eps=1),'private_result')\n",
    "result = df.applymap(func)\n",
    "export(result.describe(),'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(private_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "age_series = priv_df['Age']\n",
    "def series_map(x:float)->float:\n",
    "    return x/2\n",
    "\n",
    "result = age_series.map(series_map,eps=1,na_action='ignore')\n",
    "export( result.describe(eps=1), 'private_result')\n",
    "export( df['Age'].map(series_map,na_action='ignore') , 'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "export(priv_df[['Age','Salary']].describe(eps=1) , 'original')\n",
    "export((-priv_df[['Age','Salary']]).describe(eps=1) , 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative.columns = [\"Age_neg\",\"Salary_neg\"]\n",
    "print(original.join(negative , how=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "pdf = priv_df[['Age','Salary']]\n",
    "result1 = pdf + (10*pdf)  # expected min-max => Age:(198,660) ,  Salary:(44000,220000)\n",
    "result2 = result1/1000 # expected min-max => Age:(0.198,0.66) ,  Salary:(44,220)\n",
    "export(result1.describe(eps=1) , 'result1')\n",
    "export(result2.describe(eps=1) , 'result2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.columns = [\"Age2\",\"Salary2\"]\n",
    "result1.columns = [\"Age1\",\"Salary1\"]\n",
    "print(result1.join(result2 , how=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ag_utils import export\n",
    "# series1 and series2 should have mean roughly equal to 0.5\n",
    "series1 = PrivateSeries(pd.Series(np.random.randint(0,2,size=100000)),metadata=(0,1))\n",
    "series2 = PrivateSeries(pd.Series(np.random.randint(0,2,size=100000)),metadata=(0,1))\n",
    "or_result = series1 | series2 # should have mean around 0.75\n",
    "export(or_result.describe(eps=0.1),'or_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ag_utils import export\n",
    "# dataframes & series\n",
    "df = pd.DataFrame(np.random.randint(0, 100, size=(1000, 4)), columns=['A','B','C','D'],\n",
    "                      index=np.random.randint(-10, 10, size=1000))\n",
    "df2 = pd.DataFrame(np.random.randint(-100, 100, size=(1000, 2)), columns=['E','F'],\n",
    "                   index=np.random.randint(-10, 10, size=1000))\n",
    "s = pd.Series(np.random.randint(0, 100, size=1000), name='SER')\n",
    "\n",
    "# corresponding Private dataframes & private series\n",
    "pdf = PrivateDataFrame(df, metadata={'A': (0, 100), 'B': (0, 100), 'C': (0, 100), 'D': (0, 100)})\n",
    "pdf2 = PrivateDataFrame(df2, metadata={'E': (-100, 100), 'F': (-100, 100)})\n",
    "ps = PrivateSeries(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag #join with dataframe\n",
    "result = pdf.join(pdf2,how=\"outer\")\n",
    "export(result.describe(eps=1),'private_result')\n",
    "result = df.join(df2,how=\"outer\")\n",
    "export(result.describe(),'original_result')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag # join with series\n",
    "result = pdf.join(ps,how=\"inner\")\n",
    "export(result.describe(eps=1),'private_result')\n",
    "result = df.join(s,how=\"inner\")\n",
    "export(result.describe(),'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "result = pdf.where(pdf > 0)\n",
    "export(result.describe(eps=1),'private_result')\n",
    "result = df.where(df > 0)\n",
    "export(result.describe(),'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from op_pandas import PrivateDataFrame , PrivateSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random_data = {\n",
    "    'Age': np.random.randint(18, 60, size=100000),\n",
    "    'Salary': np.random.randint(40000, 200000, size=100000),\n",
    "    'DOB': pd.date_range('1970-01-01', periods=100000, freq='D').strftime('%Y-%m-%d')\n",
    "}\n",
    "df = pd.DataFrame(random_data)\n",
    "priv_df = PrivateDataFrame(df,metadata={'Age':(18,60) , 'Salary':(40000,200000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "age_series = priv_df[\"Age\"]\n",
    "export(age_series.var(eps=0.1) , 'var')\n",
    "export(age_series.count(eps=0.1) , 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "age_series = priv_df[\"Age\"]\n",
    "export(age_series.percentile(eps=0.1 ,p = 0) , 'min')\n",
    "export(age_series.percentile(eps=0.1 , p =100) , 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "result = priv_df.corr(eps=2)\n",
    "export(result,'private_result')\n",
    "result = df.corr(numeric_only=True)\n",
    "export(result,'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "age = priv_df[\"Age\"]\n",
    "salary = priv_df[\"Salary\"]\n",
    "export(age.cov(salary , eps=1),'private_result')\n",
    "export(df['Age'].cov(df['Salary']),'original_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from ag_utils import export\n",
    "hist_data = priv_df.hist(column='Salary',eps=0.1)\n",
    "export(hist_data , 'hist_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dp_hist , dp_bins = hist_data\n",
    "plt.bar(dp_bins[:-1], dp_hist, width=(dp_bins[1] - dp_bins[0]) * 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ag\n",
    "from op_pandas import PrivateDataFrame , PrivateSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# randomly distributing nans in two columns with prob = 0.5\n",
    "# prob of a record not having nan = 0.25 \n",
    "# Hence expected count after dropna should be around 2500.\n",
    "choice = [1,2,np.nan]\n",
    "a = np.random.choice(choice,10000,p=[0.25,0.25,0.5])\n",
    "b = np.random.choice(choice,10000,p=[0.25,0.25,0.5])\n",
    "priv_df = PrivateDataFrame(pd.DataFrame({'a':a , 'b':b}),metadata={'a':(1,2),'b':(1,2)})\n",
    "\n",
    "\n",
    "export(priv_df.dropna(axis=0).describe(eps=1), 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comm\n",
    "%%bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
